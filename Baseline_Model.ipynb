{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNV6vWq3poHGMknYGsPdIX4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6uD8Ls8vyZm",
        "outputId": "c1c08723-30bd-473e-a27a-0494e1058692"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "16TyOq3FS47v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#################### import train data and validation ###################\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "     transforms.Resize((32, 32)),  # Resize images to 32x32\n",
        "    # transforms.RandomHorizontalFlip(),  # Data augmentation\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize images\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.RandomVerticalFlip(p=0.5),\n",
        "     transforms.RandomRotation(25)\n",
        "     #transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05)\n",
        "])\n",
        "\n",
        "# Define transformations for validation data\n",
        "val_transform = transforms.Compose([\n",
        "     transforms.Resize((32, 32)),  # Resize images to 32x32\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
        "])\n",
        "\n",
        "# Set the path to the dataset\n",
        "data_dir = '/content/drive/My Drive/360_project_data'\n",
        "\n",
        "# Load the training dataset\n",
        "train_dataset = datasets.ImageFolder(data_dir + '/truncated_train', transform=train_transform)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_dataset = datasets.ImageFolder(data_dir + '/truncated_val', transform=val_transform)\n",
        "\n",
        "# Number of samples in the training and validation datasets\n",
        "print(f'Number of training samples: {len(train_dataset)}')\n",
        "print(f'Number of validation samples: {len(val_dataset)}')\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "# Create data loaders for training and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkWLJ3Il7_fo",
        "outputId": "bd935f2a-3d27-42ba-a9a2-3541167365fc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 6020\n",
            "Number of validation samples: 1290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for validation data\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Set the path to the dataset\n",
        "data_dir = '/content/drive/My Drive/360_project_data'\n",
        "\n",
        "# Load the training dataset\n",
        "train_dataset = datasets.ImageFolder(data_dir + '/truncated_train', transform=transform)\n",
        "\n",
        "# Load the validation dataset\n",
        "val_dataset = datasets.ImageFolder(data_dir + '/truncated_val', transform=transform)\n",
        "\n",
        "# Number of samples in the training and validation datasets\n",
        "print(f'Number of training samples: {len(train_dataset)}')\n",
        "print(f'Number of validation samples: {len(val_dataset)}')\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "# Create data loaders for training and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "afL1GymH9MnA",
        "outputId": "8e6958c9-3507-4a7e-9fcd-4c9a68f99e62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 6020\n",
            "Number of validation samples: 1290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########training set sanity check############\n",
        "def show_loader_samples(loader, num_batches=1):\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "        print(f'Batch {i+1}:')\n",
        "        print(f' - Images shape: {images.shape}')\n",
        "        print(f' - Labels shape: {labels.shape}')\n",
        "        if i+1 == num_batches:\n",
        "            break\n",
        "\n",
        "# Display information for 1 batch from the training and validation loaders\n",
        "print(\"Sample training batch:\")\n",
        "show_loader_samples(train_loader)\n",
        "\n",
        "print(\"Sample validation batch:\")\n",
        "show_loader_samples(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMX9BZSN8nxb",
        "outputId": "83d82364-9a44-4494-e0f8-299df64c954d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample training batch:\n",
            "Batch 1:\n",
            " - Images shape: torch.Size([32, 3, 32, 32])\n",
            " - Labels shape: torch.Size([32])\n",
            "Sample validation batch:\n",
            "Batch 1:\n",
            " - Images shape: torch.Size([32, 3, 32, 32])\n",
            " - Labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet-5: Pytorch Implementation\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        # Convolutional layers for 3-channel RGB input\n",
        "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(10 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 10 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "i_J5FeXWVSZ5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # --- Training Phase ---\n",
        "        model.train() #Set the model to training mode\n",
        "        train_loss = 0.0\n",
        "        correct_train = 0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            #############################################\n",
        "            print(f\"Processing batch...\")\n",
        "\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "            out = model(imgs)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "\n",
        "            # Accumulate training loss and correct predictions\n",
        "            train_loss += loss.item() * imgs.size(0)\n",
        "            _, predicted = torch.max(out, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # Average training loss and accuracy\n",
        "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_accuracy = 100 * correct_train / len(train_loader.dataset)\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                #############################################\n",
        "                #To Enable GPU Usage\n",
        "                if use_cuda and torch.cuda.is_available():\n",
        "                  imgs = imgs.cuda()\n",
        "                  labels = labels.cuda()\n",
        "                #############################################\n",
        "\n",
        "                # Forward pass\n",
        "                out = model(imgs)\n",
        "                loss = criterion(out, labels)\n",
        "\n",
        "                # Accumulate validation loss and correct predictions\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "                _, predicted = torch.max(out, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        # Average validation loss and accuracy\n",
        "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = 100 * correct_val / len(val_loader.dataset)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "1_hO5uCNtDJd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "model = LeNet5(num_classes=43) # GTSRB has 43 classes\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "train(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4CEXvO275iXB",
        "outputId": "1b617a14-af7d-4988-a8f8-fe31142bc44c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Epoch [1/10], Train Loss: 3.2465, Train Acc: 9.29%, Val Loss: 2.6679, Val Acc: 20.93%\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n",
            "Processing batch...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-58b23b2b7207>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA is not available.  Training on CPU ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-ffbb5d7140cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcorrect_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m#############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#To Enable GPU Usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}